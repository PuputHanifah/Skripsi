{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PuputHanifah/Skripsi/blob/main/predict_bidang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Merak"
      ],
      "metadata": {
        "id": "nD5RprcnlD9E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKvzDTtBGpFx"
      },
      "outputs": [],
      "source": [
        "import warnings; warnings.simplefilter('ignore')\n",
        "\n",
        "try:\n",
        "    import google.colab; IN_COLAB = True\n",
        "    print(\"Installing the required modules\")\n",
        "    !pip install protobuf==4.24.4 --q\n",
        "    !pip install bitsandbytes==0.41.1 --q\n",
        "    !pip install transformers==4.34.1 --q\n",
        "    !pip install peft==0.5.0 --q\n",
        "    !pip install accelerate==0.26.0 --q\n",
        "    !pip install einops==0.6.1 scipy sentencepiece datasets --q\n",
        "    !pip install transformers peft datasets --q\n",
        "    print(\"preparing directories and assets\")\n",
        "    !mkdir data images output models\n",
        "    #!wget https://raw.githubusercontent.com/taudata...\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running the code locally, please make sure all the python module versions agree with colab environment and all data/assets downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxmOLZNAGpFz"
      },
      "outputs": [],
      "source": [
        "import torch, numpy as np\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig, LlamaTokenizer\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "\"Done\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge6bhLwsGpF0"
      },
      "outputs": [],
      "source": [
        "model_id = \"Ichsan2895/Merak-7B-v4\"\n",
        "config = AutoConfig.from_pretrained(model_id)\n",
        "\n",
        "BNB_CONFIG = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                                bnb_4bit_use_double_quant=True,\n",
        "                                bnb_4bit_quant_type=\"nf4\",)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                             quantization_config=BNB_CONFIG,\n",
        "                                             device_map=\"auto\",\n",
        "                                             trust_remote_code=True)\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
        "\"Done\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD9WeLm_GpF1"
      },
      "outputs": [],
      "source": [
        "def generate_response(question: str) -> str:\n",
        "    chat = [\n",
        "      {\"role\": \"system\", \"content\": \"Anda adalah Merak, sebuah model kecerdasan buatan yang dilatih oleh Muhammad Ichsan. Mohon jawab pertanyaan berikut dengan benar, faktual, dan ramah.\"},\n",
        "      {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                           attention_mask=inputs.attention_mask,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           pad_token_id=tokenizer.eos_token_id,\n",
        "                           max_new_tokens=256)\n",
        "        response = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
        "\n",
        "        assistant_start = f'''{question} \\n assistant\\n '''\n",
        "        response_start = response.find(assistant_start)\n",
        "        return response[response_start + len(assistant_start) :].strip()\n",
        "\n",
        "\"Done\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Database"
      ],
      "metadata": {
        "id": "vlG-a9f3lKiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conMysql(dbPar, maxTry=7, verbose=False):\n",
        "    try_ = 0 # dbPar = {'db_': 'rpi', 'usr':'root', 'pas':'', 'hst':'localhost'}\n",
        "    while try_<maxTry:\n",
        "        try:\n",
        "            con =  pymysql.connect(host=dbPar['host'],user=dbPar['user'],passwd=dbPar['pass'],db=dbPar['db_'])\n",
        "            if verbose:\n",
        "                with con.cursor() as cur:\n",
        "                    cur.execute('SELECT VERSION()')\n",
        "                    version = cur.fetchone()\n",
        "                    print(f'Connected! Current Database version: {version[0]}')\n",
        "            return con\n",
        "        except (pymysql.Error) as e:\n",
        "            print (\"Error Connecting to MySQL %d: %s \\n Retrying after 3 seconds ... \" % (e.args[0],e.args[1]))\n",
        "            try_ += 1; time.sleep(3)"
      ],
      "metadata": {
        "id": "SHOV-z9rlJ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Bidang"
      ],
      "metadata": {
        "id": "Mk89XFijmZTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictBidang(status):\n",
        "\tkategori = [\"ekonomi\", \"politik\", \"sosial\", \"budaya\", \"pendidikan\", \"keamana\", \"lingkungan\", \"teknologi\", \"kesehatan\"]\n",
        "\tprompt_ = 'apa kategori yang cocok dari kalimat berikut \"{}\". apakah {} ?'.format(status, ', '.join(kategori))\n",
        "\tjawaban = generate_response(prompt_)\n",
        "\tfor cat in kategori:\n",
        "\t\tif cat.lower().strip() in jawaban:\n",
        "\t\t\treturn cat.lower().strip()\n",
        "return False"
      ],
      "metadata": {
        "id": "RqPboJDSmbg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    table = \"religion\"\n",
        "    dbTau = {'db_': 'pi', 'tblKey': '', 'tblLang':'', 'user':'fstuinjkt', 'pass':'TauData#123', 'host':'localhost'} # DB local\n",
        "    maxTry = 7\n",
        "    nBatch = 10\n",
        "    nSleep = 60\n",
        "\n",
        "    print(\"Testing Database Connection ... \", end='', flush=True)\n",
        "    try:\n",
        "        con = conMysql(dbTau, maxTry=maxTry, verbose=True)\n",
        "        con.close(); del con\n",
        "        print(\" Connected to database '{}' \".format(dbTau['host']), end='', flush=True)\n",
        "    except Exception as err_:\n",
        "        print(err_)\n",
        "        sys.exit(\"Program terminated because unable to connect to the database.\")\n"
      ],
      "metadata": {
        "id": "NTT8kUzFok5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        # ========================= 1. Ambil Data =========================\n",
        "        print(\"Ambil data dari database.\", flush=True)\n",
        "        db = conMysql(dbTau, maxTry=maxTry, verbose=False)\n",
        "        qry1 = f\"\"\"\n",
        "        SELECT id_, title, snippet\n",
        "        FROM {table}\n",
        "        WHERE bidang IS NULL AND entity NOT IN ('hajiUmroh', 'hajiUmroh2')\n",
        "        {nBatch}\n",
        "        \"\"\"\n",
        "        df = None\n",
        "        try:\n",
        "            df = pd.read_sql(qry1, db)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "       # ========================= 2. Prediksi Bidang =========================\n",
        "        if df is not None and not df.empty:\n",
        "            for i, d in df.iterrows():\n",
        "                status = f\"{d.title} {d.snippet}\"\n",
        "                bidang_ = predictBidang(status)\n",
        "                qry2 = f\"\"\"\n",
        "                UPDATE {table}\n",
        "                SET bidang = '{bidang_}'\n",
        "                WHERE id_ = {d.id_}\n",
        "                \"\"\"\n",
        "                with db.cursor() as cur:\n",
        "                    cur.execute(qry2)\n",
        "                    db.commit()\n",
        "\n",
        "            db.close()\n",
        "            print(\"Data selesai diprediksi. Melanjutkan ...\")\n",
        "\n",
        "        if df is None and df.empty:\n",
        "            print(\"Data habis. Menunggu data baru ...\")\n",
        "            for i in range(nSleep):\n",
        "                time.sleep(1)\n",
        "                print(\"Zz .. \", end=\"\", flush=True, end=\"\")\n",
        "            print()"
      ],
      "metadata": {
        "id": "FLm-G-w0pOxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize with AI"
      ],
      "metadata": {
        "id": "tgo4Z7A-H_kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import time\n",
        "import pymysql\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from typing import List\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# Load model Merak LLM\n",
        "model_id = \"Ichsan2895/Merak-7B-v4\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=None,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Fungsi untuk memanfaatkan model Merak sebagai ringkasan\n",
        "def generate_summary(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Fungsi ini akan menggunakan model Merak untuk melakukan ringkasan teks.\n",
        "    \"\"\"\n",
        "    chat = [\n",
        "        {\"role\": \"system\", \"content\": \"Anda adalah Merak, sebuah model kecerdasan buatan yang dilatih oleh Muhammad Ichsan. Tolong buat ringkasan dari teks berikut dengan jelas dan padat.\"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "\n",
        "    # Gunakan tokenizer untuk mengubah prompt menjadi token\n",
        "    prompt = tokenizer(chat, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Generate ringkasan menggunakan model\n",
        "        outputs = model.generate(\n",
        "            input_ids=prompt[\"input_ids\"].to(\"cuda\"),\n",
        "            attention_mask=prompt[\"attention_mask\"].to(\"cuda\"),\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            max_new_tokens=150  # Maksimum jumlah kata di ringkasan\n",
        "        )\n",
        "\n",
        "        # Decode hasil dari token kembali ke teks\n",
        "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Koneksi ke Database\n",
        "def conMysql(dbPar, maxTry=7, verbose=False):\n",
        "    try_ = 0\n",
        "    while try_ < maxTry:\n",
        "        try:\n",
        "            con = pymysql.connect(\n",
        "                host=dbPar['host'], user=dbPar['user'], passwd=dbPar['pass'], db=dbPar['db_']\n",
        "            )\n",
        "            if verbose:\n",
        "                with con.cursor() as cur:\n",
        "                    cur.execute('SELECT VERSION()')\n",
        "                    version = cur.fetchone()\n",
        "                    print(f\"Connected! Database version: {version[0]}\")\n",
        "            return con\n",
        "        except pymysql.Error as e:\n",
        "            print(f\"Error Connecting to MySQL {e.args[0]}: {e.args[1]} Retrying...\")\n",
        "            try_ += 1\n",
        "            time.sleep(3)\n",
        "    raise ConnectionError(\"Could not connect to database after several retries.\")\n",
        "\n",
        "# Ambil data dari database dan tampilkan ringkasan berdasarkan bidang\n",
        "def summarize_and_display():\n",
        "    table = \"religion\"\n",
        "    dbTau = {\n",
        "        'db_': 'pi',\n",
        "        'tblKey': '',\n",
        "        'tblLang': '',\n",
        "        'user': 'fstuinjkt',\n",
        "        'pass': 'TauData#123',\n",
        "        'host': 'localhost'\n",
        "    }\n",
        "\n",
        "    # Koneksi database\n",
        "    db = conMysql(dbTau, maxTry=7, verbose=True)\n",
        "\n",
        "    # Ambil data dari database\n",
        "    qry = f\"\"\"\n",
        "    SELECT bidang, title, snippet\n",
        "    FROM {table}\n",
        "    WHERE bidang IS NOT NULL\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_sql(qry, db)\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching data:\", e)\n",
        "        db.close()\n",
        "        return\n",
        "\n",
        "    # Kelompokkan berdasarkan bidang\n",
        "    grouped = df.groupby('bidang')\n",
        "\n",
        "    # Proses setiap bidang dan tampilkan ringkasan\n",
        "    for bidang, data in grouped:\n",
        "        print(f\"\\n{'='*30}\\nRingkasan untuk bidang: {bidang}\\n{'='*30}\")\n",
        "\n",
        "        # Gabungkan semua data dari title dan snippet\n",
        "        combined_text = \" \".join(data['title'].fillna('') + \" \" + data['snippet'].fillna(''))\n",
        "\n",
        "        # Gunakan fungsi LLM Merak untuk merangkum\n",
        "        summary = generate_summary(combined_text)\n",
        "\n",
        "        # Tampilkan hasil\n",
        "        print(summary)\n",
        "\n",
        "    # Tutup koneksi database\n",
        "    db.close()\n",
        "    print(\"\\nRingkasan selesai ditampilkan.\")\n",
        "\n",
        "# Jalankan fungsi utama\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Memulai proses ringkasan dengan model Merak...\")\n",
        "    summarize_and_display()"
      ],
      "metadata": {
        "id": "KJpIg2IQHz2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "vp": {
      "vp_config_version": "1.0.0",
      "vp_menu_width": 273,
      "vp_note_display": false,
      "vp_note_width": 0,
      "vp_position": {
        "width": 278
      },
      "vp_section_display": false,
      "vp_signature": "VisualPython"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}